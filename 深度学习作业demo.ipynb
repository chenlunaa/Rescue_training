{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba2f3593",
   "metadata": {},
   "source": [
    "这个是深度学习课后的小作业，主要是给大家再熟悉一下模型训练的流程，让大家体验一下。我们这里的任务是对10个类别的“时装”图像进行分类，使用[FashionMNIST数据集](https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion )。 \n",
    "FashionMNIST数据集中包含已经预先划分好的训练集和测试集，其中训练集共60,000张图像，测试集共10,000张图像。每张图像均为单通道黑白图像，大小为28\\*28pixel，分属10个类别。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd159071",
   "metadata": {},
   "source": [
    "**首先导入必要的包** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "927d4420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121e9da3",
   "metadata": {},
   "source": [
    "**配置训练环境和超参数** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a2392e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置GPU，这里有两种方式\n",
    "## 方案一：使用os.environ\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# 方案二：使用“device”，后续对要使用GPU的变量用.to(device)即可\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## 配置其他超参数，如batch_size, num_workers, learning rate, 以及总的epochs\n",
    "batch_size = 256\n",
    "num_workers = 0   # 对于Windows用户，这里应设置为0，否则会出现多线程错误\n",
    "lr = 1e-4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e06dc2",
   "metadata": {},
   "source": [
    "**数据读入和加载**  \n",
    "这里同时展示两种方式:  \n",
    "- 下载并使用PyTorch提供的内置数据集  \n",
    "- 从网站下载以csv格式存储的数据，读入并转成预期的格式    \n",
    "第一种数据读入方式只适用于常见的数据集，如MNIST，CIFAR10等，PyTorch官方提供了数据下载。这种方式往往适用于快速测试方法（比如测试下某个idea在MNIST数据集上是否有效）  \n",
    "第二种数据读入方式需要自己构建Dataset，这对于PyTorch应用于自己的工作中十分重要  \n",
    "  \n",
    "同时，还需要对数据进行必要的变换，比如说需要将图片统一为一致的大小，以便后续能够输入网络训练；需要将数据格式转为Tensor类，等等。\n",
    "  \n",
    "**我们实际比赛的时候数据加载和处理是一个非常关键的步骤。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3947bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先设置数据变换\n",
    "from torchvision import transforms\n",
    "\n",
    "image_size = 28\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  \n",
    "     # 这一步取决于后续的数据读取方式，如果使用内置数据集读取方式则不需要\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a86217a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 读取方式一：使用torchvision自带数据集，下载可能需要一段时间\n",
    "# from torchvision import datasets\n",
    "\n",
    "# train_data = datasets.FashionMNIST(root='./', train=True, download=True, transform=data_transform)\n",
    "# test_data = datasets.FashionMNIST(root='./', train=False, download=True, transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7e5a1003",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取方式二：读入csv格式的数据，自行构建Dataset类\n",
    "# csv数据下载链接：https://www.kaggle.com/zalando-research/fashionmnist\n",
    "class FMDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.images = df.iloc[:,1:].values.astype(np.uint8)\n",
    "        self.labels = df.iloc[:, 0].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(28,28,1)\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image/255., dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "train_df = pd.read_csv(\"./FashionMNIST/fashion-mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"./FashionMNIST/fashion-mnist_test.csv\")\n",
    "train_data = FMDataset(train_df, data_transform)\n",
    "test_data = FMDataset(test_df, data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb0b8b1",
   "metadata": {},
   "source": [
    "在构建训练和测试数据集完成后，需要定义DataLoader类，以便在训练和测试时加载数据  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a1d8f3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069a065",
   "metadata": {},
   "source": [
    "读入后，我们可以做一些数据可视化操作，主要是验证我们读入的数据是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "784617fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e39ff292e0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = next(iter(train_loader))\n",
    "print(image.shape, label.shape)\n",
    "plt.imshow(image[0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded3b04",
   "metadata": {},
   "source": [
    "**模型设计**  \n",
    "由于任务较为简单，这里我们手搭一个CNN，而不考虑当下各种模型的复杂结构，模型构建完成后，将模型放到GPU上用于训练。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8817a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*4*4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(-1, 64*4*4)\n",
    "        x = self.fc(x)\n",
    "        # x = nn.functional.normalize(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "model = model.cuda()\n",
    "# model = nn.DataParallel(model).cuda()   # 多卡训练时的写法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67c0f8",
   "metadata": {},
   "source": [
    "**设定损失函数**  \n",
    "使用torch.nn模块自带的CrossEntropy损失  \n",
    "PyTorch会自动把整数型的label转为one-hot型，用于计算CE loss  \n",
    "这里需要确保label是从0开始的，同时模型不加softmax层（使用logits计算）,这也说明了PyTorch训练中各个部分不是独立的，需要通盘考虑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "680b8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.CrossEntropyLoss(weight=[1,1,1,1,3,1,1,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eda2704",
   "metadata": {},
   "source": [
    "**设定优化器**  \n",
    "这里我们使用Adam优化器 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0315515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f395c64",
   "metadata": {},
   "source": [
    "**训练流程（自己写）**\n",
    "调⽤model.train()\n",
    "(1) 从train_dataloader中加载数据\n",
    "(2) 计算损失函数\n",
    "(3) 反向传播，优化器优化\n",
    "(4) print展⽰输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6cb6bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    total_train_step = 0\n",
    "    for i in range(epoch):\n",
    "        total_test_loss = 0\n",
    "        total_acc_sum = 0\n",
    "        print(\"-----------------第{}轮训练开始--------------------\".format(i+1))\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            imgs, targets = data\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_test_loss += loss.item()\n",
    "            acc_sum = (outputs.argmax(1) == targets).sum().item()\n",
    "            total_acc_sum += acc_sum\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_step = total_train_step + 1\n",
    "            if total_train_step % 100 == 0:\n",
    "                print(\"训练次数: {}, Loss: {}\".format(total_train_step, loss.item()))\n",
    "        print(\"整体训练上的loss: {}\".format(total_test_loss))\n",
    "        print(\"整体训练上的acc: {}\".format(total_acc_sum / (train_data.__len__() )))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bdb39f",
   "metadata": {},
   "source": [
    "**验证流程（自己写）**\n",
    "关注两者的主要区别：  \n",
    "- 模型状态设置  \n",
    "- 是否需要初始化优化器\n",
    "- 是否需要将loss传回到网络\n",
    "- 是否需要每步更新optimizer  \n",
    "  \n",
    "此外，对于测试或验证过程，可以计算分类准确率，要求把结果print出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a44cb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    total_test_step = 0\n",
    "    total_test_loss = 0\n",
    "    total_acc_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            imgs, targets = data\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_test_loss = total_test_loss + loss.item()\n",
    "            acc_sum = (outputs.argmax(1) == targets).sum().item()\n",
    "            total_acc_sum = total_acc_sum + acc_sum\n",
    "\n",
    "    print (\"整体测试数据集上的Loss: {}\".format(total_test_loss))\n",
    "    print (\"整体测试数据集上的acc: {}\".format(total_acc_sum / (test_data.__len__() )))\n",
    "    total_test_step = total_test_step + 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f524f896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.5487737059593201\n",
      "训练次数: 200, Loss: 0.49675455689430237\n",
      "整体训练上的loss: 159.23691868782043\n",
      "整体训练上的acc: 0.7446833333333334\n",
      "整体测试数据集上的Loss: 18.003009647130966\n",
      "整体测试数据集上的acc: 0.8376\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.46815672516822815\n",
      "训练次数: 200, Loss: 0.3526226878166199\n",
      "整体训练上的loss: 102.30776056647301\n",
      "整体训练上的acc: 0.8382333333333334\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.38241490721702576\n",
      "训练次数: 400, Loss: 0.33788856863975525\n",
      "整体训练上的loss: 85.49100184440613\n",
      "整体训练上的acc: 0.8636333333333334\n",
      "整体测试数据集上的Loss: 12.423908069729805\n",
      "整体测试数据集上的acc: 0.8892\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.2564340829849243\n",
      "训练次数: 200, Loss: 0.34448137879371643\n",
      "整体训练上的loss: 77.64192074537277\n",
      "整体训练上的acc: 0.8775166666666666\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.31526708602905273\n",
      "训练次数: 400, Loss: 0.29326409101486206\n",
      "整体训练上的loss: 71.2707199305296\n",
      "整体训练上的acc: 0.88725\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.3032630980014801\n",
      "训练次数: 600, Loss: 0.3026167154312134\n",
      "训练次数: 700, Loss: 0.31913572549819946\n",
      "整体训练上的loss: 68.5286839902401\n",
      "整体训练上的acc: 0.8910833333333333\n",
      "整体测试数据集上的Loss: 10.591973826289177\n",
      "整体测试数据集上的acc: 0.8999\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.24808578193187714\n",
      "训练次数: 200, Loss: 0.2695608139038086\n",
      "整体训练上的loss: 63.78565275669098\n",
      "整体训练上的acc: 0.89615\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.2729424834251404\n",
      "训练次数: 400, Loss: 0.20978426933288574\n",
      "整体训练上的loss: 62.19771961867809\n",
      "整体训练上的acc: 0.9004166666666666\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.2772981822490692\n",
      "训练次数: 600, Loss: 0.25613391399383545\n",
      "训练次数: 700, Loss: 0.2249692678451538\n",
      "整体训练上的loss: 58.6750323176384\n",
      "整体训练上的acc: 0.9062333333333333\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.21700622141361237\n",
      "训练次数: 900, Loss: 0.19158318638801575\n",
      "整体训练上的loss: 56.66395674645901\n",
      "整体训练上的acc: 0.9081166666666667\n",
      "整体测试数据集上的Loss: 8.895295098423958\n",
      "整体测试数据集上的acc: 0.9158\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.20690494775772095\n",
      "训练次数: 200, Loss: 0.23261503875255585\n",
      "整体训练上的loss: 54.41413666307926\n",
      "整体训练上的acc: 0.9109666666666667\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.23648664355278015\n",
      "训练次数: 400, Loss: 0.209531769156456\n",
      "整体训练上的loss: 52.63485775142908\n",
      "整体训练上的acc: 0.9148333333333334\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.3106628358364105\n",
      "训练次数: 600, Loss: 0.20971539616584778\n",
      "训练次数: 700, Loss: 0.21290165185928345\n",
      "整体训练上的loss: 51.12209506332874\n",
      "整体训练上的acc: 0.9169333333333334\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.20799654722213745\n",
      "训练次数: 900, Loss: 0.15586408972740173\n",
      "整体训练上的loss: 48.796258978545666\n",
      "整体训练上的acc: 0.9203833333333333\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.21052756905555725\n",
      "训练次数: 1100, Loss: 0.2613680362701416\n",
      "整体训练上的loss: 47.433391720056534\n",
      "整体训练上的acc: 0.9224833333333333\n",
      "整体测试数据集上的Loss: 8.70909084379673\n",
      "整体测试数据集上的acc: 0.9203\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.20168882608413696\n",
      "训练次数: 200, Loss: 0.19577248394489288\n",
      "整体训练上的loss: 46.3296947106719\n",
      "整体训练上的acc: 0.9244666666666667\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.1718693971633911\n",
      "训练次数: 400, Loss: 0.2061917781829834\n",
      "整体训练上的loss: 44.875416442751884\n",
      "整体训练上的acc: 0.9255833333333333\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.18594016134738922\n",
      "训练次数: 600, Loss: 0.17117440700531006\n",
      "训练次数: 700, Loss: 0.17335659265518188\n",
      "整体训练上的loss: 43.785493075847626\n",
      "整体训练上的acc: 0.9281833333333334\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.194123312830925\n",
      "训练次数: 900, Loss: 0.1855488121509552\n",
      "整体训练上的loss: 42.74122143536806\n",
      "整体训练上的acc: 0.92845\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.1318211555480957\n",
      "训练次数: 1100, Loss: 0.12309534102678299\n",
      "整体训练上的loss: 40.80280104279518\n",
      "整体训练上的acc: 0.9329666666666667\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.1514740139245987\n",
      "训练次数: 1300, Loss: 0.1654682755470276\n",
      "训练次数: 1400, Loss: 0.15823879837989807\n",
      "整体训练上的loss: 40.34241461753845\n",
      "整体训练上的acc: 0.93395\n",
      "整体测试数据集上的Loss: 8.011790946125984\n",
      "整体测试数据集上的acc: 0.9259\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.12284643203020096\n",
      "训练次数: 200, Loss: 0.1309802383184433\n",
      "整体训练上的loss: 38.93977618962526\n",
      "整体训练上的acc: 0.9362333333333334\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.1002405658364296\n",
      "训练次数: 400, Loss: 0.1495860069990158\n",
      "整体训练上的loss: 37.661168575286865\n",
      "整体训练上的acc: 0.9365833333333333\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.14990530908107758\n",
      "训练次数: 600, Loss: 0.12214472144842148\n",
      "训练次数: 700, Loss: 0.11087244749069214\n",
      "整体训练上的loss: 37.12119613587856\n",
      "整体训练上的acc: 0.9378\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.17426998913288116\n",
      "训练次数: 900, Loss: 0.12383418530225754\n",
      "整体训练上的loss: 36.29784655570984\n",
      "整体训练上的acc: 0.9405666666666667\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.11653856933116913\n",
      "训练次数: 1100, Loss: 0.14783409237861633\n",
      "整体训练上的loss: 34.90550219267607\n",
      "整体训练上的acc: 0.9416166666666667\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.13981181383132935\n",
      "训练次数: 1300, Loss: 0.11356600373983383\n",
      "训练次数: 1400, Loss: 0.17883481085300446\n",
      "整体训练上的loss: 34.28912338614464\n",
      "整体训练上的acc: 0.9423666666666667\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.11872576922178268\n",
      "训练次数: 1600, Loss: 0.2000533491373062\n",
      "整体训练上的loss: 33.11634864658117\n",
      "整体训练上的acc: 0.9445666666666667\n",
      "整体测试数据集上的Loss: 7.937901549041271\n",
      "整体测试数据集上的acc: 0.927\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.14069736003875732\n",
      "训练次数: 200, Loss: 0.11836893856525421\n",
      "整体训练上的loss: 32.35565550625324\n",
      "整体训练上的acc: 0.9461833333333334\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.13355733454227448\n",
      "训练次数: 400, Loss: 0.13586588203907013\n",
      "整体训练上的loss: 31.09579861536622\n",
      "整体训练上的acc: 0.9494666666666667\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.1627790331840515\n",
      "训练次数: 600, Loss: 0.12055185437202454\n",
      "训练次数: 700, Loss: 0.12474463880062103\n",
      "整体训练上的loss: 30.80663987249136\n",
      "整体训练上的acc: 0.9481333333333334\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.11400796473026276\n",
      "训练次数: 900, Loss: 0.14689697325229645\n",
      "整体训练上的loss: 29.452466569840908\n",
      "整体训练上的acc: 0.9505666666666667\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.1056240051984787\n",
      "训练次数: 1100, Loss: 0.1066594198346138\n",
      "整体训练上的loss: 28.902563244104385\n",
      "整体训练上的acc: 0.9515666666666667\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.10746177285909653\n",
      "训练次数: 1300, Loss: 0.10823525488376617\n",
      "训练次数: 1400, Loss: 0.20914138853549957\n",
      "整体训练上的loss: 28.771160379052162\n",
      "整体训练上的acc: 0.9521833333333334\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.0912087932229042\n",
      "训练次数: 1600, Loss: 0.16468791663646698\n",
      "整体训练上的loss: 27.91886391863227\n",
      "整体训练上的acc: 0.9528\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.09076562523841858\n",
      "训练次数: 1800, Loss: 0.14245282113552094\n",
      "整体训练上的loss: 27.406319104135036\n",
      "整体训练上的acc: 0.9540833333333333\n",
      "整体测试数据集上的Loss: 8.691494423896074\n",
      "整体测试数据集上的acc: 0.9237\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.08304829895496368\n",
      "训练次数: 200, Loss: 0.12794415652751923\n",
      "整体训练上的loss: 26.962508600205183\n",
      "整体训练上的acc: 0.9546333333333333\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.12687815725803375\n",
      "训练次数: 400, Loss: 0.1355394870042801\n",
      "整体训练上的loss: 26.336113765835762\n",
      "整体训练上的acc: 0.9555\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.06000376492738724\n",
      "训练次数: 600, Loss: 0.08160821348428726\n",
      "训练次数: 700, Loss: 0.1278313398361206\n",
      "整体训练上的loss: 25.09470073506236\n",
      "整体训练上的acc: 0.9578166666666666\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.08959002047777176\n",
      "训练次数: 900, Loss: 0.0950639545917511\n",
      "整体训练上的loss: 24.64923571422696\n",
      "整体训练上的acc: 0.9583833333333334\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.07416398823261261\n",
      "训练次数: 1100, Loss: 0.1101740300655365\n",
      "整体训练上的loss: 24.122673850506544\n",
      "整体训练上的acc: 0.9596166666666667\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.06951534748077393\n",
      "训练次数: 1300, Loss: 0.10184802114963531\n",
      "训练次数: 1400, Loss: 0.1349031776189804\n",
      "整体训练上的loss: 23.674664054065943\n",
      "整体训练上的acc: 0.9590333333333333\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.1023319810628891\n",
      "训练次数: 1600, Loss: 0.1286548227071762\n",
      "整体训练上的loss: 23.877143912017345\n",
      "整体训练上的acc: 0.9600333333333333\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.04554818198084831\n",
      "训练次数: 1800, Loss: 0.1234467625617981\n",
      "整体训练上的loss: 23.430030591785908\n",
      "整体训练上的acc: 0.9606333333333333\n",
      "-----------------第9轮训练开始--------------------\n",
      "训练次数: 1900, Loss: 0.08517476916313171\n",
      "训练次数: 2000, Loss: 0.1326185017824173\n",
      "训练次数: 2100, Loss: 0.12182454764842987\n",
      "整体训练上的loss: 22.828941021114588\n",
      "整体训练上的acc: 0.9606333333333333\n",
      "整体测试数据集上的Loss: 8.86097401380539\n",
      "整体测试数据集上的acc: 0.9281\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.12000802159309387\n",
      "训练次数: 200, Loss: 0.11221785098314285\n",
      "整体训练上的loss: 22.465440597385168\n",
      "整体训练上的acc: 0.96295\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.1108526960015297\n",
      "训练次数: 400, Loss: 0.1613948494195938\n",
      "整体训练上的loss: 21.607523795217276\n",
      "整体训练上的acc: 0.9638\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.05331987142562866\n",
      "训练次数: 600, Loss: 0.09528546780347824\n",
      "训练次数: 700, Loss: 0.1085604578256607\n",
      "整体训练上的loss: 21.627615954726934\n",
      "整体训练上的acc: 0.9629333333333333\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.08029404282569885\n",
      "训练次数: 900, Loss: 0.09241645038127899\n",
      "整体训练上的loss: 20.58786892145872\n",
      "整体训练上的acc: 0.9652166666666666\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.11242212355136871\n",
      "训练次数: 1100, Loss: 0.05334874615073204\n",
      "整体训练上的loss: 21.686928410083055\n",
      "整体训练上的acc: 0.9631333333333333\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.06977240741252899\n",
      "训练次数: 1300, Loss: 0.06036670506000519\n",
      "训练次数: 1400, Loss: 0.057666558772325516\n",
      "整体训练上的loss: 20.61369912698865\n",
      "整体训练上的acc: 0.9653333333333334\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.05765260010957718\n",
      "训练次数: 1600, Loss: 0.04194164648652077\n",
      "整体训练上的loss: 19.638462092727423\n",
      "整体训练上的acc: 0.9661833333333333\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.08784608542919159\n",
      "训练次数: 1800, Loss: 0.07170215249061584\n",
      "整体训练上的loss: 20.3221753872931\n",
      "整体训练上的acc: 0.9653833333333334\n",
      "-----------------第9轮训练开始--------------------\n",
      "训练次数: 1900, Loss: 0.05181802809238434\n",
      "训练次数: 2000, Loss: 0.07307557016611099\n",
      "训练次数: 2100, Loss: 0.10147803276777267\n",
      "整体训练上的loss: 19.1983594968915\n",
      "整体训练上的acc: 0.9675166666666667\n",
      "-----------------第10轮训练开始--------------------\n",
      "训练次数: 2200, Loss: 0.0734623596072197\n",
      "训练次数: 2300, Loss: 0.1161155104637146\n",
      "整体训练上的loss: 19.524316238239408\n",
      "整体训练上的acc: 0.9672333333333333\n",
      "整体测试数据集上的Loss: 9.46957229822874\n",
      "整体测试数据集上的acc: 0.9255\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.10848146677017212\n",
      "训练次数: 200, Loss: 0.07647475600242615\n",
      "整体训练上的loss: 18.87656127847731\n",
      "整体训练上的acc: 0.9678166666666667\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.07761771231889725\n",
      "训练次数: 400, Loss: 0.07197962701320648\n",
      "整体训练上的loss: 18.390885330736637\n",
      "整体训练上的acc: 0.96845\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.06999126821756363\n",
      "训练次数: 600, Loss: 0.08376264572143555\n",
      "训练次数: 700, Loss: 0.077691949903965\n",
      "整体训练上的loss: 18.31229281798005\n",
      "整体训练上的acc: 0.9698\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.09476205706596375\n",
      "训练次数: 900, Loss: 0.0696365088224411\n",
      "整体训练上的loss: 18.595966447144747\n",
      "整体训练上的acc: 0.9684833333333334\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.07554154098033905\n",
      "训练次数: 1100, Loss: 0.05944066867232323\n",
      "整体训练上的loss: 18.03322921320796\n",
      "整体训练上的acc: 0.9692833333333334\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.0571896918118\n",
      "训练次数: 1300, Loss: 0.08760114014148712\n",
      "训练次数: 1400, Loss: 0.057776015251874924\n",
      "整体训练上的loss: 17.930403973907232\n",
      "整体训练上的acc: 0.9701\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.06493988633155823\n",
      "训练次数: 1600, Loss: 0.06383056938648224\n",
      "整体训练上的loss: 16.969828771427274\n",
      "整体训练上的acc: 0.9711833333333333\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.08280038833618164\n",
      "训练次数: 1800, Loss: 0.09181933850049973\n",
      "整体训练上的loss: 17.957193180918694\n",
      "整体训练上的acc: 0.96925\n",
      "-----------------第9轮训练开始--------------------\n",
      "训练次数: 1900, Loss: 0.10585390031337738\n",
      "训练次数: 2000, Loss: 0.08299518376588821\n",
      "训练次数: 2100, Loss: 0.07461348921060562\n",
      "整体训练上的loss: 16.859152721241117\n",
      "整体训练上的acc: 0.9714666666666667\n",
      "-----------------第10轮训练开始--------------------\n",
      "训练次数: 2200, Loss: 0.06833123415708542\n",
      "训练次数: 2300, Loss: 0.05947955697774887\n",
      "整体训练上的loss: 17.12747150287032\n",
      "整体训练上的acc: 0.9712\n",
      "-----------------第11轮训练开始--------------------\n",
      "训练次数: 2400, Loss: 0.03137299418449402\n",
      "训练次数: 2500, Loss: 0.10050185769796371\n",
      "整体训练上的loss: 16.905469547957182\n",
      "整体训练上的acc: 0.9714166666666667\n",
      "整体测试数据集上的Loss: 10.142014385201037\n",
      "整体测试数据集上的acc: 0.9249\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.07705994695425034\n",
      "训练次数: 200, Loss: 0.0729123055934906\n",
      "整体训练上的loss: 16.254556983709335\n",
      "整体训练上的acc: 0.9721\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.07457779347896576\n",
      "训练次数: 400, Loss: 0.04157981649041176\n",
      "整体训练上的loss: 16.881406150758266\n",
      "整体训练上的acc: 0.9715333333333334\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.06458571553230286\n",
      "训练次数: 600, Loss: 0.1040850579738617\n",
      "训练次数: 700, Loss: 0.04816408455371857\n",
      "整体训练上的loss: 16.482105296105146\n",
      "整体训练上的acc: 0.9718\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.10226232558488846\n",
      "训练次数: 900, Loss: 0.09961000084877014\n",
      "整体训练上的loss: 16.329167515039444\n",
      "整体训练上的acc: 0.9716333333333333\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.050580043345689774\n",
      "训练次数: 1100, Loss: 0.055436160415410995\n",
      "整体训练上的loss: 15.205308686941862\n",
      "整体训练上的acc: 0.9739166666666667\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.03922209143638611\n",
      "训练次数: 1300, Loss: 0.044618990272283554\n",
      "训练次数: 1400, Loss: 0.07748639583587646\n",
      "整体训练上的loss: 16.171354174613953\n",
      "整体训练上的acc: 0.9728\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.06313484907150269\n",
      "训练次数: 1600, Loss: 0.06033826246857643\n",
      "整体训练上的loss: 15.458291601389647\n",
      "整体训练上的acc: 0.9738833333333333\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.05079629644751549\n",
      "训练次数: 1800, Loss: 0.0420796163380146\n",
      "整体训练上的loss: 15.018854215741158\n",
      "整体训练上的acc: 0.9744\n",
      "-----------------第9轮训练开始--------------------\n",
      "训练次数: 1900, Loss: 0.065240278840065\n",
      "训练次数: 2000, Loss: 0.08549579977989197\n",
      "训练次数: 2100, Loss: 0.04651085287332535\n",
      "整体训练上的loss: 15.50076910853386\n",
      "整体训练上的acc: 0.9743\n",
      "-----------------第10轮训练开始--------------------\n",
      "训练次数: 2200, Loss: 0.046578601002693176\n",
      "训练次数: 2300, Loss: 0.048889774829149246\n",
      "整体训练上的loss: 14.76695641130209\n",
      "整体训练上的acc: 0.9755833333333334\n",
      "-----------------第11轮训练开始--------------------\n",
      "训练次数: 2400, Loss: 0.044500067830085754\n",
      "训练次数: 2500, Loss: 0.04613819345831871\n",
      "整体训练上的loss: 15.131209775805473\n",
      "整体训练上的acc: 0.9738\n",
      "-----------------第12轮训练开始--------------------\n",
      "训练次数: 2600, Loss: 0.0911751240491867\n",
      "训练次数: 2700, Loss: 0.04793880507349968\n",
      "训练次数: 2800, Loss: 0.05572710931301117\n",
      "整体训练上的loss: 15.231436599045992\n",
      "整体训练上的acc: 0.97465\n",
      "整体测试数据集上的Loss: 10.958290431532077\n",
      "整体测试数据集上的acc: 0.9239\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.02129269763827324\n",
      "训练次数: 200, Loss: 0.06215066835284233\n",
      "整体训练上的loss: 13.392174830660224\n",
      "整体训练上的acc: 0.9777333333333333\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.08178170770406723\n",
      "训练次数: 400, Loss: 0.047573696821928024\n",
      "整体训练上的loss: 14.656871099025011\n",
      "整体训练上的acc: 0.9748833333333333\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.07170209288597107\n",
      "训练次数: 600, Loss: 0.07728220522403717\n",
      "训练次数: 700, Loss: 0.06083861365914345\n",
      "整体训练上的loss: 14.670166241005063\n",
      "整体训练上的acc: 0.9757666666666667\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.052885692566633224\n",
      "训练次数: 900, Loss: 0.06184937432408333\n",
      "整体训练上的loss: 14.105738269165158\n",
      "整体训练上的acc: 0.9761166666666666\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.04785127565264702\n",
      "训练次数: 1100, Loss: 0.035091739147901535\n",
      "整体训练上的loss: 13.875617306679487\n",
      "整体训练上的acc: 0.9769666666666666\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.0244138166308403\n",
      "训练次数: 1300, Loss: 0.055888839066028595\n",
      "训练次数: 1400, Loss: 0.045639798045158386\n",
      "整体训练上的loss: 14.020556949079037\n",
      "整体训练上的acc: 0.9759666666666666\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.05980786681175232\n",
      "训练次数: 1600, Loss: 0.03766951337456703\n",
      "整体训练上的loss: 14.072759578935802\n",
      "整体训练上的acc: 0.9759833333333333\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.05057794228196144\n",
      "训练次数: 1800, Loss: 0.04704706370830536\n",
      "整体训练上的loss: 13.877276163548231\n",
      "整体训练上的acc: 0.9764166666666667\n",
      "-----------------第9轮训练开始--------------------\n",
      "训练次数: 1900, Loss: 0.08703038096427917\n",
      "训练次数: 2000, Loss: 0.03231917321681976\n",
      "训练次数: 2100, Loss: 0.06397474557161331\n",
      "整体训练上的loss: 13.731860047206283\n",
      "整体训练上的acc: 0.97645\n",
      "-----------------第10轮训练开始--------------------\n",
      "训练次数: 2200, Loss: 0.07833681255578995\n",
      "训练次数: 2300, Loss: 0.08374086767435074\n",
      "整体训练上的loss: 13.848704848438501\n",
      "整体训练上的acc: 0.9766833333333333\n",
      "-----------------第11轮训练开始--------------------\n",
      "训练次数: 2400, Loss: 0.06971430033445358\n",
      "训练次数: 2500, Loss: 0.04939226806163788\n",
      "整体训练上的loss: 13.197679404169321\n",
      "整体训练上的acc: 0.9779666666666667\n",
      "-----------------第12轮训练开始--------------------\n",
      "训练次数: 2600, Loss: 0.032855622470378876\n",
      "训练次数: 2700, Loss: 0.0739714503288269\n",
      "训练次数: 2800, Loss: 0.0592414028942585\n",
      "整体训练上的loss: 13.169943670742214\n",
      "整体训练上的acc: 0.9776333333333334\n",
      "-----------------第13轮训练开始--------------------\n",
      "训练次数: 2900, Loss: 0.06663217395544052\n",
      "训练次数: 3000, Loss: 0.16051824390888214\n",
      "整体训练上的loss: 13.550290807150304\n",
      "整体训练上的acc: 0.9774833333333334\n",
      "整体测试数据集上的Loss: 12.082088887691498\n",
      "整体测试数据集上的acc: 0.9235\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.10786490142345428\n",
      "训练次数: 200, Loss: 0.061268117278814316\n",
      "整体训练上的loss: 12.85378011316061\n",
      "整体训练上的acc: 0.9780833333333333\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.06172957643866539\n",
      "训练次数: 400, Loss: 0.09040850400924683\n",
      "整体训练上的loss: 12.464280426502228\n",
      "整体训练上的acc: 0.9791666666666666\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.06672423332929611\n",
      "训练次数: 600, Loss: 0.02355164848268032\n",
      "训练次数: 700, Loss: 0.09403061121702194\n",
      "整体训练上的loss: 13.519630992785096\n",
      "整体训练上的acc: 0.9768\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.06494501233100891\n",
      "训练次数: 900, Loss: 0.06916368752717972\n",
      "整体训练上的loss: 12.885587198659778\n",
      "整体训练上的acc: 0.9788166666666667\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.06390233337879181\n",
      "训练次数: 1100, Loss: 0.06949497759342194\n",
      "整体训练上的loss: 12.571827158331871\n",
      "整体训练上的acc: 0.9780833333333333\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.04692072421312332\n",
      "训练次数: 1300, Loss: 0.04056066274642944\n",
      "训练次数: 1400, Loss: 0.07673957943916321\n",
      "整体训练上的loss: 12.284840761683881\n",
      "整体训练上的acc: 0.9793666666666667\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.038729485124349594\n",
      "训练次数: 1600, Loss: 0.07468473166227341\n",
      "整体训练上的loss: 12.65414266847074\n",
      "整体训练上的acc: 0.9783333333333334\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.05415923148393631\n",
      "训练次数: 1800, Loss: 0.038367871195077896\n",
      "整体训练上的loss: 11.842901304364204\n",
      "整体训练上的acc: 0.9799166666666667\n",
      "-----------------第9轮训练开始--------------------\n",
      "训练次数: 1900, Loss: 0.02973867394030094\n",
      "训练次数: 2000, Loss: 0.026367422193288803\n",
      "训练次数: 2100, Loss: 0.08228521794080734\n",
      "整体训练上的loss: 12.206190327182412\n",
      "整体训练上的acc: 0.979\n",
      "-----------------第10轮训练开始--------------------\n",
      "训练次数: 2200, Loss: 0.021291488781571388\n",
      "训练次数: 2300, Loss: 0.04501156881451607\n",
      "整体训练上的loss: 12.146014032885432\n",
      "整体训练上的acc: 0.9790833333333333\n",
      "-----------------第11轮训练开始--------------------\n",
      "训练次数: 2400, Loss: 0.028345728293061256\n",
      "训练次数: 2500, Loss: 0.07191438227891922\n",
      "整体训练上的loss: 12.298533409833908\n",
      "整体训练上的acc: 0.97905\n",
      "-----------------第12轮训练开始--------------------\n",
      "训练次数: 2600, Loss: 0.0765102282166481\n",
      "训练次数: 2700, Loss: 0.06419646739959717\n",
      "训练次数: 2800, Loss: 0.07273915410041809\n",
      "整体训练上的loss: 12.739152502268553\n",
      "整体训练上的acc: 0.9786166666666667\n",
      "-----------------第13轮训练开始--------------------\n",
      "训练次数: 2900, Loss: 0.08105798065662384\n",
      "训练次数: 3000, Loss: 0.06683341413736343\n",
      "整体训练上的loss: 12.229299412108958\n",
      "整体训练上的acc: 0.9791833333333333\n",
      "-----------------第14轮训练开始--------------------\n",
      "训练次数: 3100, Loss: 0.038946483284235\n",
      "训练次数: 3200, Loss: 0.03479382023215294\n",
      "整体训练上的loss: 12.060221235267818\n",
      "整体训练上的acc: 0.9793833333333334\n",
      "整体测试数据集上的Loss: 12.623200260102749\n",
      "整体测试数据集上的acc: 0.9261\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.05769461765885353\n",
      "训练次数: 200, Loss: 0.05448073521256447\n",
      "整体训练上的loss: 12.310153134167194\n",
      "整体训练上的acc: 0.9791833333333333\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.06432830542325974\n",
      "训练次数: 400, Loss: 0.061311230063438416\n",
      "整体训练上的loss: 11.799218045547605\n",
      "整体训练上的acc: 0.9796\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.0443432591855526\n",
      "训练次数: 600, Loss: 0.06623073667287827\n",
      "训练次数: 700, Loss: 0.08327600359916687\n",
      "整体训练上的loss: 11.415378768928349\n",
      "整体训练上的acc: 0.98045\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.07592581957578659\n",
      "训练次数: 900, Loss: 0.0638076439499855\n",
      "整体训练上的loss: 11.582347283139825\n",
      "整体训练上的acc: 0.98095\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.028868984431028366\n",
      "训练次数: 1100, Loss: 0.03286993131041527\n",
      "整体训练上的loss: 11.903746502939612\n",
      "整体训练上的acc: 0.97975\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.06257021427154541\n",
      "训练次数: 1300, Loss: 0.02653474546968937\n",
      "训练次数: 1400, Loss: 0.02979801595211029\n",
      "整体训练上的loss: 11.935288089327514\n",
      "整体训练上的acc: 0.98\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.06512665748596191\n",
      "训练次数: 1600, Loss: 0.04601534828543663\n",
      "整体训练上的loss: 11.747822978068143\n",
      "整体训练上的acc: 0.9800333333333333\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.0588734894990921\n",
      "训练次数: 1800, Loss: 0.07668828219175339\n",
      "整体训练上的loss: 11.380878050811589\n",
      "整体训练上的acc: 0.98055\n",
      "-----------------第9轮训练开始--------------------\n",
      "训练次数: 1900, Loss: 0.038678959012031555\n",
      "训练次数: 2000, Loss: 0.03228364512324333\n",
      "训练次数: 2100, Loss: 0.053466927260160446\n",
      "整体训练上的loss: 11.058682172559202\n",
      "整体训练上的acc: 0.9803833333333334\n",
      "-----------------第10轮训练开始--------------------\n",
      "训练次数: 2200, Loss: 0.05743527412414551\n",
      "训练次数: 2300, Loss: 0.06101326644420624\n",
      "整体训练上的loss: 11.404916854575276\n",
      "整体训练上的acc: 0.9813\n",
      "-----------------第11轮训练开始--------------------\n",
      "训练次数: 2400, Loss: 0.05084351822733879\n",
      "训练次数: 2500, Loss: 0.04608147591352463\n",
      "整体训练上的loss: 11.490683949552476\n",
      "整体训练上的acc: 0.9800333333333333\n",
      "-----------------第12轮训练开始--------------------\n",
      "训练次数: 2600, Loss: 0.07840290665626526\n",
      "训练次数: 2700, Loss: 0.04062463715672493\n",
      "训练次数: 2800, Loss: 0.06132469326257706\n",
      "整体训练上的loss: 11.262690428644419\n",
      "整体训练上的acc: 0.9809\n",
      "-----------------第13轮训练开始--------------------\n",
      "训练次数: 2900, Loss: 0.02238607592880726\n",
      "训练次数: 3000, Loss: 0.025424771010875702\n",
      "整体训练上的loss: 10.842752695083618\n",
      "整体训练上的acc: 0.98155\n",
      "-----------------第14轮训练开始--------------------\n",
      "训练次数: 3100, Loss: 0.024723511189222336\n",
      "训练次数: 3200, Loss: 0.03324508294463158\n",
      "整体训练上的loss: 11.082453892566264\n",
      "整体训练上的acc: 0.9810666666666666\n",
      "-----------------第15轮训练开始--------------------\n",
      "训练次数: 3300, Loss: 0.015599390491843224\n",
      "训练次数: 3400, Loss: 0.03253113478422165\n",
      "训练次数: 3500, Loss: 0.08305422216653824\n",
      "整体训练上的loss: 10.9184939134866\n",
      "整体训练上的acc: 0.9815\n",
      "整体测试数据集上的Loss: 13.3002405539155\n",
      "整体测试数据集上的acc: 0.9259\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.028240693733096123\n",
      "训练次数: 200, Loss: 0.049113016575574875\n",
      "整体训练上的loss: 11.493210472166538\n",
      "整体训练上的acc: 0.9804166666666667\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.06631341576576233\n",
      "训练次数: 400, Loss: 0.04421215504407883\n",
      "整体训练上的loss: 11.687008360400796\n",
      "整体训练上的acc: 0.98065\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.037193991243839264\n",
      "训练次数: 600, Loss: 0.03057534620165825\n",
      "训练次数: 700, Loss: 0.037199076265096664\n",
      "整体训练上的loss: 10.835635362192988\n",
      "整体训练上的acc: 0.9815333333333334\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.03818236663937569\n",
      "训练次数: 900, Loss: 0.025185832753777504\n",
      "整体训练上的loss: 11.151293594855815\n",
      "整体训练上的acc: 0.9813833333333334\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.05136231333017349\n",
      "训练次数: 1100, Loss: 0.10770587623119354\n",
      "整体训练上的loss: 11.181649693287909\n",
      "整体训练上的acc: 0.9812\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.08865292370319366\n",
      "训练次数: 1300, Loss: 0.031885843724012375\n",
      "训练次数: 1400, Loss: 0.019652461633086205\n",
      "整体训练上的loss: 10.455003528855741\n",
      "整体训练上的acc: 0.9820333333333333\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.05730685964226723\n",
      "训练次数: 1600, Loss: 0.017053348943591118\n",
      "整体训练上的loss: 10.760809974744916\n",
      "整体训练上的acc: 0.98145\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.07041174918413162\n",
      "训练次数: 1800, Loss: 0.021319599822163582\n",
      "整体训练上的loss: 10.68720281496644\n",
      "整体训练上的acc: 0.9818833333333333\n",
      "-----------------第9轮训练开始--------------------\n",
      "训练次数: 1900, Loss: 0.03314049914479256\n",
      "训练次数: 2000, Loss: 0.03481170907616615\n",
      "训练次数: 2100, Loss: 0.05868155136704445\n",
      "整体训练上的loss: 10.545557615347207\n",
      "整体训练上的acc: 0.98225\n",
      "-----------------第10轮训练开始--------------------\n",
      "训练次数: 2200, Loss: 0.036031465977430344\n",
      "训练次数: 2300, Loss: 0.06359376013278961\n",
      "整体训练上的loss: 12.075851040892303\n",
      "整体训练上的acc: 0.97985\n",
      "-----------------第11轮训练开始--------------------\n",
      "训练次数: 2400, Loss: 0.026768887415528297\n",
      "训练次数: 2500, Loss: 0.04680228233337402\n",
      "整体训练上的loss: 10.690921753179282\n",
      "整体训练上的acc: 0.9819166666666667\n",
      "-----------------第12轮训练开始--------------------\n",
      "训练次数: 2600, Loss: 0.060025494545698166\n",
      "训练次数: 2700, Loss: 0.033664245158433914\n",
      "训练次数: 2800, Loss: 0.03664388880133629\n",
      "整体训练上的loss: 10.85143224336207\n",
      "整体训练上的acc: 0.9823666666666667\n",
      "-----------------第13轮训练开始--------------------\n",
      "训练次数: 2900, Loss: 0.061536625027656555\n",
      "训练次数: 3000, Loss: 0.0291639044880867\n",
      "整体训练上的loss: 10.847487960476428\n",
      "整体训练上的acc: 0.9814833333333334\n",
      "-----------------第14轮训练开始--------------------\n",
      "训练次数: 3100, Loss: 0.03262239322066307\n",
      "训练次数: 3200, Loss: 0.020156394690275192\n",
      "整体训练上的loss: 10.405801981687546\n",
      "整体训练上的acc: 0.98275\n",
      "-----------------第15轮训练开始--------------------\n",
      "训练次数: 3300, Loss: 0.0837976336479187\n",
      "训练次数: 3400, Loss: 0.036623772233724594\n",
      "训练次数: 3500, Loss: 0.05125218257308006\n",
      "整体训练上的loss: 10.582645650953054\n",
      "整体训练上的acc: 0.9815833333333334\n",
      "-----------------第16轮训练开始--------------------\n",
      "训练次数: 3600, Loss: 0.062004413455724716\n",
      "训练次数: 3700, Loss: 0.01844692975282669\n",
      "整体训练上的loss: 10.499648750759661\n",
      "整体训练上的acc: 0.9823333333333333\n",
      "整体测试数据集上的Loss: 13.36844601482153\n",
      "整体测试数据集上的acc: 0.9275\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.0736328661441803\n",
      "训练次数: 200, Loss: 0.032715633511543274\n",
      "整体训练上的loss: 10.194477781653404\n",
      "整体训练上的acc: 0.9822666666666666\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.04265422746539116\n",
      "训练次数: 400, Loss: 0.022218981757760048\n",
      "整体训练上的loss: 10.419837466441095\n",
      "整体训练上的acc: 0.9822166666666666\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.029384886845946312\n",
      "训练次数: 600, Loss: 0.044255636632442474\n",
      "训练次数: 700, Loss: 0.06413090229034424\n",
      "整体训练上的loss: 10.16495743021369\n",
      "整体训练上的acc: 0.9825333333333334\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.02911527268588543\n",
      "训练次数: 900, Loss: 0.037393614649772644\n",
      "整体训练上的loss: 10.159983405843377\n",
      "整体训练上的acc: 0.9828333333333333\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.03397377207875252\n",
      "训练次数: 1100, Loss: 0.027624793350696564\n",
      "整体训练上的loss: 10.358916975557804\n",
      "整体训练上的acc: 0.9824166666666667\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.08292456716299057\n",
      "训练次数: 1300, Loss: 0.07390653342008591\n",
      "训练次数: 1400, Loss: 0.03469996526837349\n",
      "整体训练上的loss: 10.064905425533652\n",
      "整体训练上的acc: 0.9825833333333334\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.03548251837491989\n",
      "训练次数: 1600, Loss: 0.0557590126991272\n",
      "整体训练上的loss: 9.900066649541259\n",
      "整体训练上的acc: 0.98355\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.0766449049115181\n",
      "训练次数: 1800, Loss: 0.03995458409190178\n",
      "整体训练上的loss: 10.026451303157955\n",
      "整体训练上的acc: 0.98295\n",
      "-----------------第9轮训练开始--------------------\n",
      "训练次数: 1900, Loss: 0.008504897356033325\n",
      "训练次数: 2000, Loss: 0.052961595356464386\n",
      "训练次数: 2100, Loss: 0.04161708056926727\n",
      "整体训练上的loss: 9.610054014250636\n",
      "整体训练上的acc: 0.9838666666666667\n",
      "-----------------第10轮训练开始--------------------\n",
      "训练次数: 2200, Loss: 0.019173454493284225\n",
      "训练次数: 2300, Loss: 0.025121444836258888\n",
      "整体训练上的loss: 10.827891896478832\n",
      "整体训练上的acc: 0.9816\n",
      "-----------------第11轮训练开始--------------------\n",
      "训练次数: 2400, Loss: 0.03943244740366936\n",
      "训练次数: 2500, Loss: 0.05067451298236847\n",
      "整体训练上的loss: 10.084538116119802\n",
      "整体训练上的acc: 0.9825833333333334\n",
      "-----------------第12轮训练开始--------------------\n",
      "训练次数: 2600, Loss: 0.028122635558247566\n",
      "训练次数: 2700, Loss: 0.03845918923616409\n",
      "训练次数: 2800, Loss: 0.04937485605478287\n",
      "整体训练上的loss: 10.149755355436355\n",
      "整体训练上的acc: 0.9828833333333333\n",
      "-----------------第13轮训练开始--------------------\n",
      "训练次数: 2900, Loss: 0.03356010466814041\n",
      "训练次数: 3000, Loss: 0.08269627392292023\n",
      "整体训练上的loss: 9.83945219963789\n",
      "整体训练上的acc: 0.9832666666666666\n",
      "-----------------第14轮训练开始--------------------\n",
      "训练次数: 3100, Loss: 0.03668569400906563\n",
      "训练次数: 3200, Loss: 0.027172422036528587\n",
      "整体训练上的loss: 9.231781519949436\n",
      "整体训练上的acc: 0.9842166666666666\n",
      "-----------------第15轮训练开始--------------------\n",
      "训练次数: 3300, Loss: 0.036882102489471436\n",
      "训练次数: 3400, Loss: 0.036671631038188934\n",
      "训练次数: 3500, Loss: 0.021838121116161346\n",
      "整体训练上的loss: 9.580597857944667\n",
      "整体训练上的acc: 0.9836166666666667\n",
      "-----------------第16轮训练开始--------------------\n",
      "训练次数: 3600, Loss: 0.019463444128632545\n",
      "训练次数: 3700, Loss: 0.06339932233095169\n",
      "整体训练上的loss: 10.590545629151165\n",
      "整体训练上的acc: 0.98235\n",
      "-----------------第17轮训练开始--------------------\n",
      "训练次数: 3800, Loss: 0.045962974429130554\n",
      "训练次数: 3900, Loss: 0.04562440514564514\n",
      "整体训练上的loss: 10.001616602763534\n",
      "整体训练上的acc: 0.9831833333333333\n",
      "整体测试数据集上的Loss: 14.150282993912697\n",
      "整体测试数据集上的acc: 0.9269\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.025937369093298912\n",
      "训练次数: 200, Loss: 0.06753812730312347\n",
      "整体训练上的loss: 9.897827698849142\n",
      "整体训练上的acc: 0.9830666666666666\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.048795878887176514\n",
      "训练次数: 400, Loss: 0.023857425898313522\n",
      "整体训练上的loss: 9.487961567007005\n",
      "整体训练上的acc: 0.9838166666666667\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.022266527637839317\n",
      "训练次数: 600, Loss: 0.038589853793382645\n",
      "训练次数: 700, Loss: 0.02222093567252159\n",
      "整体训练上的loss: 9.360304632689804\n",
      "整体训练上的acc: 0.9844\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.02231556363403797\n",
      "训练次数: 900, Loss: 0.011714549735188484\n",
      "整体训练上的loss: 9.543887510430068\n",
      "整体训练上的acc: 0.9841833333333333\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.04870181158185005\n",
      "训练次数: 1100, Loss: 0.0396675281226635\n",
      "整体训练上的loss: 9.26588218472898\n",
      "整体训练上的acc: 0.984\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.032568395137786865\n",
      "训练次数: 1300, Loss: 0.03362925723195076\n",
      "训练次数: 1400, Loss: 0.07156532257795334\n",
      "整体训练上的loss: 9.727032020688057\n",
      "整体训练上的acc: 0.9835333333333334\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.08745076507329941\n",
      "训练次数: 1600, Loss: 0.0477827750146389\n",
      "整体训练上的loss: 9.046953395940363\n",
      "整体训练上的acc: 0.9846333333333334\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.04142998531460762\n",
      "训练次数: 1800, Loss: 0.055058542639017105\n",
      "整体训练上的loss: 9.246567338705063\n",
      "整体训练上的acc: 0.9845833333333334\n",
      "-----------------第9轮训练开始--------------------\n",
      "训练次数: 1900, Loss: 0.0331079363822937\n",
      "训练次数: 2000, Loss: 0.02284035086631775\n",
      "训练次数: 2100, Loss: 0.021321836858987808\n",
      "整体训练上的loss: 9.24318652274087\n",
      "整体训练上的acc: 0.9850666666666666\n",
      "-----------------第10轮训练开始--------------------\n",
      "训练次数: 2200, Loss: 0.03861295059323311\n",
      "训练次数: 2300, Loss: 0.026801908388733864\n",
      "整体训练上的loss: 9.617973885498941\n",
      "整体训练上的acc: 0.9839\n",
      "-----------------第11轮训练开始--------------------\n",
      "训练次数: 2400, Loss: 0.011635988019406796\n",
      "训练次数: 2500, Loss: 0.026148973032832146\n",
      "整体训练上的loss: 9.01570394076407\n",
      "整体训练上的acc: 0.9847\n",
      "-----------------第12轮训练开始--------------------\n",
      "训练次数: 2600, Loss: 0.018394876271486282\n",
      "训练次数: 2700, Loss: 0.08799014985561371\n",
      "训练次数: 2800, Loss: 0.07136744260787964\n",
      "整体训练上的loss: 9.604304075241089\n",
      "整体训练上的acc: 0.9841666666666666\n",
      "-----------------第13轮训练开始--------------------\n",
      "训练次数: 2900, Loss: 0.014787180349230766\n",
      "训练次数: 3000, Loss: 0.05803169310092926\n",
      "整体训练上的loss: 9.933009650558233\n",
      "整体训练上的acc: 0.9835166666666667\n",
      "-----------------第14轮训练开始--------------------\n",
      "训练次数: 3100, Loss: 0.027414513751864433\n",
      "训练次数: 3200, Loss: 0.01537818368524313\n",
      "整体训练上的loss: 8.529062275774777\n",
      "整体训练上的acc: 0.9855833333333334\n",
      "-----------------第15轮训练开始--------------------\n",
      "训练次数: 3300, Loss: 0.06188688054680824\n",
      "训练次数: 3400, Loss: 0.049476757645606995\n",
      "训练次数: 3500, Loss: 0.0301254540681839\n",
      "整体训练上的loss: 9.649483643937856\n",
      "整体训练上的acc: 0.9839166666666667\n",
      "-----------------第16轮训练开始--------------------\n",
      "训练次数: 3600, Loss: 0.05448313429951668\n",
      "训练次数: 3700, Loss: 0.04677615687251091\n",
      "整体训练上的loss: 9.451309693045914\n",
      "整体训练上的acc: 0.9839666666666667\n",
      "-----------------第17轮训练开始--------------------\n",
      "训练次数: 3800, Loss: 0.025163279846310616\n",
      "训练次数: 3900, Loss: 0.02927452325820923\n",
      "整体训练上的loss: 8.61424158141017\n",
      "整体训练上的acc: 0.9852833333333333\n",
      "-----------------第18轮训练开始--------------------\n",
      "训练次数: 4000, Loss: 0.0461445190012455\n",
      "训练次数: 4100, Loss: 0.035642724484205246\n",
      "训练次数: 4200, Loss: 0.030861612409353256\n",
      "整体训练上的loss: 8.978462535422295\n",
      "整体训练上的acc: 0.9845666666666667\n",
      "整体测试数据集上的Loss: 14.722027562558651\n",
      "整体测试数据集上的acc: 0.9276\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.008696037344634533\n",
      "训练次数: 200, Loss: 0.017865987494587898\n",
      "整体训练上的loss: 9.145077809458598\n",
      "整体训练上的acc: 0.9845166666666667\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.08075055480003357\n",
      "训练次数: 400, Loss: 0.03404299542307854\n",
      "整体训练上的loss: 9.405994756380096\n",
      "整体训练上的acc: 0.9841833333333333\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.09981273114681244\n",
      "训练次数: 600, Loss: 0.013656292110681534\n",
      "训练次数: 700, Loss: 0.026805253699421883\n",
      "整体训练上的loss: 9.53208870254457\n",
      "整体训练上的acc: 0.98405\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.04441579431295395\n",
      "训练次数: 900, Loss: 0.031190579757094383\n",
      "整体训练上的loss: 9.39184076571837\n",
      "整体训练上的acc: 0.9845666666666667\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.019773805513978004\n",
      "训练次数: 1100, Loss: 0.03147029131650925\n",
      "整体训练上的loss: 8.670945561956614\n",
      "整体训练上的acc: 0.9851\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.04894839972257614\n",
      "训练次数: 1300, Loss: 0.04682549461722374\n",
      "训练次数: 1400, Loss: 0.018222197890281677\n",
      "整体训练上的loss: 8.705977709032595\n",
      "整体训练上的acc: 0.9852166666666666\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.027800273150205612\n",
      "训练次数: 1600, Loss: 0.08478935807943344\n",
      "整体训练上的loss: 8.589424208272249\n",
      "整体训练上的acc: 0.9854333333333334\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.022718407213687897\n",
      "训练次数: 1800, Loss: 0.05555672198534012\n",
      "整体训练上的loss: 9.24707135767676\n",
      "整体训练上的acc: 0.9847166666666667\n",
      "-----------------第9轮训练开始--------------------\n",
      "训练次数: 1900, Loss: 0.048446789383888245\n",
      "训练次数: 2000, Loss: 0.04371146485209465\n",
      "训练次数: 2100, Loss: 0.022955337539315224\n",
      "整体训练上的loss: 9.153527229093015\n",
      "整体训练上的acc: 0.9850333333333333\n",
      "-----------------第10轮训练开始--------------------\n",
      "训练次数: 2200, Loss: 0.05253380537033081\n",
      "训练次数: 2300, Loss: 0.04553312435746193\n",
      "整体训练上的loss: 8.696426481474191\n",
      "整体训练上的acc: 0.9852833333333333\n",
      "-----------------第11轮训练开始--------------------\n",
      "训练次数: 2400, Loss: 0.016644176095724106\n",
      "训练次数: 2500, Loss: 0.034188784658908844\n",
      "整体训练上的loss: 9.196817161049694\n",
      "整体训练上的acc: 0.9848833333333333\n",
      "-----------------第12轮训练开始--------------------\n",
      "训练次数: 2600, Loss: 0.03669745847582817\n",
      "训练次数: 2700, Loss: 0.029408762231469154\n",
      "训练次数: 2800, Loss: 0.030839312821626663\n",
      "整体训练上的loss: 8.789078761357814\n",
      "整体训练上的acc: 0.9853166666666666\n",
      "-----------------第13轮训练开始--------------------\n",
      "训练次数: 2900, Loss: 0.04360514134168625\n",
      "训练次数: 3000, Loss: 0.03186016529798508\n",
      "整体训练上的loss: 8.754676544107497\n",
      "整体训练上的acc: 0.9852833333333333\n",
      "-----------------第14轮训练开始--------------------\n",
      "训练次数: 3100, Loss: 0.012877561151981354\n",
      "训练次数: 3200, Loss: 0.014248008839786053\n",
      "整体训练上的loss: 8.939438736997545\n",
      "整体训练上的acc: 0.9854833333333334\n",
      "-----------------第15轮训练开始--------------------\n",
      "训练次数: 3300, Loss: 0.04167845845222473\n",
      "训练次数: 3400, Loss: 0.024461600929498672\n",
      "训练次数: 3500, Loss: 0.04385540634393692\n",
      "整体训练上的loss: 8.628467891830951\n",
      "整体训练上的acc: 0.9855833333333334\n",
      "-----------------第16轮训练开始--------------------\n",
      "训练次数: 3600, Loss: 0.028212370350956917\n",
      "训练次数: 3700, Loss: 0.044859595596790314\n",
      "整体训练上的loss: 9.358497894834727\n",
      "整体训练上的acc: 0.9841333333333333\n",
      "-----------------第17轮训练开始--------------------\n",
      "训练次数: 3800, Loss: 0.015777841210365295\n",
      "训练次数: 3900, Loss: 0.038505345582962036\n",
      "整体训练上的loss: 9.129181990399957\n",
      "整体训练上的acc: 0.9847666666666667\n",
      "-----------------第18轮训练开始--------------------\n",
      "训练次数: 4000, Loss: 0.02416990138590336\n",
      "训练次数: 4100, Loss: 0.042831044644117355\n",
      "训练次数: 4200, Loss: 0.023500027135014534\n",
      "整体训练上的loss: 9.162720528896898\n",
      "整体训练上的acc: 0.9851833333333333\n",
      "-----------------第19轮训练开始--------------------\n",
      "训练次数: 4300, Loss: 0.01657627895474434\n",
      "训练次数: 4400, Loss: 0.01222799438983202\n",
      "整体训练上的loss: 9.161930604372174\n",
      "整体训练上的acc: 0.9848666666666667\n",
      "整体测试数据集上的Loss: 14.539651438593864\n",
      "整体测试数据集上的acc: 0.927\n",
      "-----------------第1轮训练开始--------------------\n",
      "训练次数: 100, Loss: 0.029054440557956696\n",
      "训练次数: 200, Loss: 0.07446729391813278\n",
      "整体训练上的loss: 9.016897330991924\n",
      "整体训练上的acc: 0.9846833333333334\n",
      "-----------------第2轮训练开始--------------------\n",
      "训练次数: 300, Loss: 0.04978909716010094\n",
      "训练次数: 400, Loss: 0.019211821258068085\n",
      "整体训练上的loss: 8.126352479215711\n",
      "整体训练上的acc: 0.9863333333333333\n",
      "-----------------第3轮训练开始--------------------\n",
      "训练次数: 500, Loss: 0.04438963532447815\n",
      "训练次数: 600, Loss: 0.02878536842763424\n",
      "训练次数: 700, Loss: 0.029370734468102455\n",
      "整体训练上的loss: 8.850853497162461\n",
      "整体训练上的acc: 0.9850333333333333\n",
      "-----------------第4轮训练开始--------------------\n",
      "训练次数: 800, Loss: 0.032534100115299225\n",
      "训练次数: 900, Loss: 0.029267068952322006\n",
      "整体训练上的loss: 8.379021400818601\n",
      "整体训练上的acc: 0.9864\n",
      "-----------------第5轮训练开始--------------------\n",
      "训练次数: 1000, Loss: 0.07434415072202682\n",
      "训练次数: 1100, Loss: 0.03270694240927696\n",
      "整体训练上的loss: 8.568378372117877\n",
      "整体训练上的acc: 0.9855\n",
      "-----------------第6轮训练开始--------------------\n",
      "训练次数: 1200, Loss: 0.03919095918536186\n",
      "训练次数: 1300, Loss: 0.06058343127369881\n",
      "训练次数: 1400, Loss: 0.04671195521950722\n",
      "整体训练上的loss: 8.620723617263138\n",
      "整体训练上的acc: 0.9852\n",
      "-----------------第7轮训练开始--------------------\n",
      "训练次数: 1500, Loss: 0.021891824901103973\n",
      "训练次数: 1600, Loss: 0.044265374541282654\n",
      "整体训练上的loss: 8.69495057221502\n",
      "整体训练上的acc: 0.9856333333333334\n",
      "-----------------第8轮训练开始--------------------\n",
      "训练次数: 1700, Loss: 0.05008326843380928\n",
      "训练次数: 1800, Loss: 0.04722712188959122\n",
      "整体训练上的loss: 7.91473167669028\n",
      "整体训练上的acc: 0.9864166666666667\n",
      "-----------------第9轮训练开始--------------------\n",
      "训练次数: 1900, Loss: 0.038267821073532104\n",
      "训练次数: 2000, Loss: 0.06014704331755638\n",
      "训练次数: 2100, Loss: 0.017353791743516922\n",
      "整体训练上的loss: 7.720054185017943\n",
      "整体训练上的acc: 0.9863833333333333\n",
      "-----------------第10轮训练开始--------------------\n",
      "训练次数: 2200, Loss: 0.027496710419654846\n",
      "训练次数: 2300, Loss: 0.014726627618074417\n",
      "整体训练上的loss: 9.550572366453707\n",
      "整体训练上的acc: 0.9838833333333333\n",
      "-----------------第11轮训练开始--------------------\n",
      "训练次数: 2400, Loss: 0.05010659247636795\n",
      "训练次数: 2500, Loss: 0.10941393673419952\n",
      "整体训练上的loss: 8.511842037551105\n",
      "整体训练上的acc: 0.9853333333333333\n",
      "-----------------第12轮训练开始--------------------\n",
      "训练次数: 2600, Loss: 0.05166592821478844\n",
      "训练次数: 2700, Loss: 0.05696956068277359\n",
      "训练次数: 2800, Loss: 0.015137705020606518\n",
      "整体训练上的loss: 8.633836950408295\n",
      "整体训练上的acc: 0.9851666666666666\n",
      "-----------------第13轮训练开始--------------------\n",
      "训练次数: 2900, Loss: 0.08438301086425781\n",
      "训练次数: 3000, Loss: 0.004267299547791481\n",
      "整体训练上的loss: 8.812363218516111\n",
      "整体训练上的acc: 0.9859666666666667\n",
      "-----------------第14轮训练开始--------------------\n",
      "训练次数: 3100, Loss: 0.0548839308321476\n",
      "训练次数: 3200, Loss: 0.03965243324637413\n",
      "整体训练上的loss: 8.050885307602584\n",
      "整体训练上的acc: 0.9864333333333334\n",
      "-----------------第15轮训练开始--------------------\n",
      "训练次数: 3300, Loss: 0.05481012910604477\n",
      "训练次数: 3400, Loss: 0.04053184390068054\n",
      "训练次数: 3500, Loss: 0.13959066569805145\n",
      "整体训练上的loss: 8.366295508574694\n",
      "整体训练上的acc: 0.9861666666666666\n",
      "-----------------第16轮训练开始--------------------\n",
      "训练次数: 3600, Loss: 0.037808287888765335\n",
      "训练次数: 3700, Loss: 0.018760066479444504\n",
      "整体训练上的loss: 8.542037766426802\n",
      "整体训练上的acc: 0.98585\n",
      "-----------------第17轮训练开始--------------------\n",
      "训练次数: 3800, Loss: 0.08047492802143097\n",
      "训练次数: 3900, Loss: 0.0537291094660759\n",
      "整体训练上的loss: 7.91549198422581\n",
      "整体训练上的acc: 0.9863833333333333\n",
      "-----------------第18轮训练开始--------------------\n",
      "训练次数: 4000, Loss: 0.0795314759016037\n",
      "训练次数: 4100, Loss: 0.01542575377970934\n",
      "训练次数: 4200, Loss: 0.01729174703359604\n",
      "整体训练上的loss: 8.143721167230979\n",
      "整体训练上的acc: 0.9863333333333333\n",
      "-----------------第19轮训练开始--------------------\n",
      "训练次数: 4300, Loss: 0.06155300885438919\n",
      "训练次数: 4400, Loss: 0.02890549786388874\n",
      "整体训练上的loss: 8.375237024389207\n",
      "整体训练上的acc: 0.98605\n",
      "-----------------第20轮训练开始--------------------\n",
      "训练次数: 4500, Loss: 0.03296654298901558\n",
      "训练次数: 4600, Loss: 0.030576908960938454\n",
      "整体训练上的loss: 8.00112370448187\n",
      "整体训练上的acc: 0.98605\n",
      "整体测试数据集上的Loss: 15.856766283512115\n",
      "整体测试数据集上的acc: 0.9247\n"
     ]
    }
   ],
   "source": [
    "# epoch 自己设定值，这里要求设定成一个列表，看看不同epoch对结果的影响\n",
    "for epoch in range(1, epochs+1):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9bf3c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./FahionModel.pkl\"\n",
    "torch.save(model, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
